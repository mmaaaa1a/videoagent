import os
import logging
import time
from tqdm import tqdm
from faster_whisper import WhisperModel
from .._storage import IntermediateStorageManager

def speech_to_text(video_name, working_dir, segment_index2name, audio_output_format, use_epyc_optimization=False, session_id=None, progress_callback=None):
    """
    è¯­éŸ³è¯†åˆ«å‡½æ•°ï¼Œæ”¯æŒä¼ ç»Ÿæ¨¡å¼å’ŒEPYCä¼˜åŒ–æ¨¡å¼

    Args:
        video_name: è§†é¢‘åç§°
        working_dir: å·¥ä½œç›®å½•
        segment_index2name: ç‰‡æ®µç´¢å¼•æ˜ å°„
        audio_output_format: éŸ³é¢‘æ ¼å¼
        use_epyc_optimization: æ˜¯å¦ä½¿ç”¨EPYCä¼˜åŒ–æ¨¡å¼
        session_id: ä¼šè¯IDï¼Œç”¨äºä¸­é—´æ–‡ä»¶å­˜å‚¨
    """
    if use_epyc_optimization:
        try:
            # å°è¯•å¯¼å…¥EPYCä¼˜åŒ–æ¨¡å—
            from .asr_epyc_optimized import speech_to_text_epyc_optimized
            print("ğŸš€ ä½¿ç”¨EPYC 64æ ¸å¿ƒä¼˜åŒ–æ¨¡å¼")
            return speech_to_text_epyc_optimized(video_name, working_dir, segment_index2name, audio_output_format, session_id, progress_callback)
        except ImportError as e:
            print(f"âš ï¸ EPYCä¼˜åŒ–æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œé™çº§åˆ°ä¼ ç»Ÿæ¨¡å¼: {e}")
            use_epyc_optimization = False

    # ä¼ ç»Ÿæ¨¡å¼å¤„ç†
    print("ğŸ“ ä½¿ç”¨ä¼ ç»Ÿè¯­éŸ³è¯†åˆ«æ¨¡å¼")
    start_time = time.time()

    # åˆå§‹åŒ–ä¸­é—´æ–‡ä»¶å­˜å‚¨ç®¡ç†å™¨
    storage_manager = None
    if session_id:
        try:
            storage_manager = IntermediateStorageManager(session_id, working_dir)
            storage_manager.append_to_log("03_asr_transcription", f"å¼€å§‹ä¼ ç»Ÿæ¨¡å¼è¯­éŸ³è¯†åˆ«: {video_name}")
        except Exception as e:
            logging.warning(f"æ— æ³•åˆå§‹åŒ–ä¸­é—´æ–‡ä»¶å­˜å‚¨ç®¡ç†å™¨: {e}")

    # ä¿å­˜ä¼ ç»Ÿæ¨¡å¼é…ç½®
    if storage_manager:
        config = {
            "video_name": video_name,
            "audio_output_format": audio_output_format,
            "model_name": "large-v3",
            "device": "cpu",
            "use_epyc_optimization": False,
            "total_segments": len(segment_index2name)
        }
        storage_manager.save_step_config("03_asr_transcription", config)

    # ä½¿ç”¨faster-whisperå†…ç½®æ¨¡å‹ï¼Œfaster-distil-whisper-large-v3ç­‰æ•ˆäºlarge-v3
    model = WhisperModel("large-v3", device="cpu")
    model.logger.setLevel(logging.WARNING)

    cache_path = os.path.join(working_dir, '_cache', video_name)

    transcripts = {}
    successful_transcriptions = 0
    failed_transcriptions = 0
    processed_segments = 0

    for index in tqdm(segment_index2name, desc=f"Speech Recognition {video_name}"):
        segment_name = segment_index2name[index]
        audio_file = os.path.join(cache_path, f"{segment_name}.{audio_output_format}")

        # if the audio file does not exist, skip it
        if not os.path.exists(audio_file):
            transcripts[index] = ""
            failed_transcriptions += 1
            if storage_manager:
                storage_manager.append_to_log("03_asr_transcription",
                    f"è·³è¿‡ç¼ºå¤±çš„éŸ³é¢‘æ–‡ä»¶: {audio_file}", "WARNING")
            continue

        try:
            segments, info = model.transcribe(audio_file)

            # å¤„ç†transcribeå¯èƒ½è¿”å›Noneçš„æƒ…å†µ
            if segments is None:
                transcripts[index] = ""
                failed_transcriptions += 1
                if storage_manager:
                    storage_manager.append_to_log("03_asr_transcription",
                        f"è½¬å½•è¿”å›ç©ºç»“æœ: {audio_file}", "WARNING")
                continue

            result = ""
            for segment in segments:
                result += "[%.2fs -> %.2fs] %s\n" % (segment.start, segment.end, segment.text)
            transcripts[index] = result
            successful_transcriptions += 1

            # å®æ—¶ä¿å­˜æ¯ä¸ªç‰‡æ®µçš„è½¬å½•ç»“æœ
            if storage_manager:
                segment_data = {
                    "segment_id": index,
                    "audio_file": os.path.basename(audio_file),
                    "transcript": result,
                    "timestamp": time.time(),
                    "info": {
                        "language": info.language if info else "unknown",
                        "language_probability": info.language_probability if info else 0.0
                    },
                    "success": bool(result and result.strip())
                }

                step_path = storage_manager._get_step_path("03_asr_transcription")
                segment_file = step_path / "transcripts_by_segment" / f"segment_{index.zfill(3)}.json"
                storage_manager._atomic_write(segment_file, segment_data)

                # æ¯10ä¸ªç‰‡æ®µè®°å½•ä¸€æ¬¡è¿›åº¦
                if (processed_segments + 1) % 10 == 0:
                    storage_manager.append_to_log("03_asr_transcription",
                        f"å·²å¤„ç† {processed_segments + 1}/{len(segment_index2name)} ä¸ªç‰‡æ®µ")

        except Exception as e:
            transcripts[index] = ""
            failed_transcriptions += 1
            logging.error(f"è½¬å½•å¤±è´¥ {audio_file}: {e}")
            if storage_manager:
                storage_manager.append_to_log("03_asr_transcription",
                    f"è½¬å½•å¤±è´¥ {audio_file}: {str(e)}", "ERROR")

        processed_segments += 1

    # æ€§èƒ½ç»Ÿè®¡
    elapsed_time = time.time() - start_time
    avg_time_per_file = elapsed_time / len(segment_index2name) if segment_index2name else 0

    print(f"âœ… ä¼ ç»Ÿæ¨¡å¼è¯­éŸ³è¯†åˆ«å®Œæˆ:")
    print(f"   - å¤„ç†æ–‡ä»¶æ•°: {len(segment_index2name)}")
    print(f"   - æˆåŠŸè½¬å½•: {successful_transcriptions}")
    print(f"   - å¤±è´¥è½¬å½•: {failed_transcriptions}")
    print(f"   - æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
    print(f"   - å¹³å‡æ¯æ–‡ä»¶: {avg_time_per_file:.2f}ç§’")
    print(f"   - å¤„ç†é€Ÿåº¦: {len(segment_index2name)/elapsed_time:.2f}æ–‡ä»¶/ç§’")

    # ä¿å­˜å®Œæ•´ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
    if storage_manager:
        # ä¿å­˜è½¬å½•ç»“æœ
        data = {
            "video_name": video_name,
            "transcripts": transcripts,
            "total_segments": len(segment_index2name),
            "processed_segments": processed_segments,
            "successful_transcriptions": successful_transcriptions,
            "failed_transcriptions": failed_transcriptions,
            "success_rate": successful_transcriptions / processed_segments if processed_segments > 0 else 0
        }
        storage_manager.save_step_result("03_asr_transcription", data)

        # ä¿å­˜æ€§èƒ½ç»Ÿè®¡
        stats = {
            "video_name": video_name,
            "model_name": "large-v3",
            "device": "cpu",
            "total_segments": len(segment_index2name),
            "processed_segments": processed_segments,
            "successful_transcriptions": successful_transcriptions,
            "failed_transcriptions": failed_transcriptions,
            "processing_time": elapsed_time,
            "avg_time_per_file": avg_time_per_file,
            "files_per_second": len(segment_index2name) / elapsed_time if elapsed_time > 0 else 0
        }
        storage_manager.save_step_stats("03_asr_transcription", stats)

        storage_manager.append_to_log("03_asr_transcription",
            f"ä¼ ç»Ÿæ¨¡å¼ASRå®Œæˆ: {successful_transcriptions}/{processed_segments} æˆåŠŸ, è€—æ—¶ {elapsed_time:.2f}s")

    return transcripts