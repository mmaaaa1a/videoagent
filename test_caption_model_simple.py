#!/usr/bin/env python3
"""
ç®€åŒ–æµ‹è¯•VideoRAGä¿®å¤åçš„caption_modelåˆå§‹åŒ–
"""
import sys
import os

# æ·»åŠ VideoRAGç®—æ³•è·¯å¾„
sys.path.insert(0, '/data/é¡¹ç›®/videoagent/VideoRAG-algorithm')

def test_caption_model_only():
    """ä»…æµ‹è¯•caption_modelçš„åŠ è½½åŠŸèƒ½"""
    print("ğŸ”§ å¼€å§‹æµ‹è¯•caption_modelåŠ è½½...")

    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['USE_GGUF_CAPTION'] = 'true'
        os.environ['CAPTION_MODEL_PATH'] = '/data/é¡¹ç›®/videoagent/models/MiniCPM-o-2_6-gguf/.cache/huggingface/download/Model-7.6B-Q4_K_M.gguf'

        print("âœ… ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ")

        # å¯¼å…¥LLMConfig
        from videorag._llm import openai_config

        print("âœ… LLMConfigå¯¼å…¥æˆåŠŸ")

        # åˆ›å»ºä¸€ä¸ªæœ€å°çš„VideoRAGç±»æ¥æµ‹è¯•caption_modelåŠ è½½
        from dataclasses import dataclass, field

        @dataclass
        class TestVideoRAG:
            working_dir: str = "./storage/test"

            def load_caption_model(self, debug=False):
                # è¿™æ˜¯VideoRAGä¸­çš„load_caption_modelæ–¹æ³•çš„æ ¸å¿ƒä»£ç 
                if not debug:
                    use_gguf = os.getenv('USE_GGUF_CAPTION', 'false').lower() == 'true'

                    if use_gguf:
                        # ä½¿ç”¨GGUFæ¨¡å‹
                        from llama_cpp import Llama
                        model_path = os.getenv('CAPTION_MODEL_PATH', '/data/é¡¹ç›®/videoagent/models/MiniCPM-o-2_6-gguf/.cache/huggingface/download/Model-7.6B-Q4_K_M.gguf')
                        self.caption_model = Llama(
                            model_path=model_path,
                            n_ctx=int(os.getenv('GGUF_CONTEXT_SIZE', '4096')),
                            n_gpu_layers=0,
                            n_threads=int(os.getenv('GGUF_N_THREADS', '32')),
                            verbose=False,
                            n_batch=int(os.getenv('GGUF_BATCH_SIZE', '64'))
                        )
                        self.caption_tokenizer = None  # GGUFä¸éœ€è¦tokenizer
                    else:
                        # ä½¿ç”¨åŸæœ‰MiniCPM-Væ¨¡å‹
                        from transformers import AutoModel, AutoTokenizer
                        self.caption_model = AutoModel.from_pretrained('./MiniCPM-V-2_6-int4', trust_remote_code=True)
                        self.caption_tokenizer = AutoTokenizer.from_pretrained('./MiniCPM-V-2_6-int4', trust_remote_code=True)
                        self.caption_model.eval()
                else:
                    self.caption_model = None
                    self.caption_tokenizer = None

        print("âœ… æµ‹è¯•ç±»åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•caption_modelåŠ è½½
        test_videorag = TestVideoRAG()
        test_videorag.load_caption_model()

        print("âœ… caption_modelåŠ è½½å®Œæˆ")

        # æ£€æŸ¥ç»“æœ
        if hasattr(test_videorag, 'caption_model') and test_videorag.caption_model is not None:
            print("âœ… caption_modelå±æ€§å­˜åœ¨ä¸”ä¸ä¸ºNone")
            print(f"   æ¨¡å‹ç±»å‹: {type(test_videorag.caption_model)}")

            # ç®€å•æµ‹è¯•
            try:
                response = test_videorag.caption_model(
                    "Hello, how are you?",
                    max_tokens=10,
                    temperature=0.1
                )
                print("âœ… caption_modelåŠŸèƒ½æµ‹è¯•é€šè¿‡")
                print(f"   æµ‹è¯•å“åº”: {response}")
                return True
            except Exception as e:
                print(f"âš ï¸ caption_modelåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
                return False
        else:
            print("âŒ caption_modelå±æ€§ä¸å­˜åœ¨æˆ–ä¸ºNone")
            return False

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_videorag_with_existing_config():
    """ä½¿ç”¨ç°æœ‰é…ç½®æµ‹è¯•VideoRAG"""
    print("\nğŸ”§ å¼€å§‹æµ‹è¯•VideoRAGç°æœ‰é…ç½®...")

    try:
        # å¯¼å…¥VideoRAG
        from videorag import VideoRAG
        print("âœ… VideoRAGæ¨¡å—å¯¼å…¥æˆåŠŸ")

        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä½¿ç”¨é¡¹ç›®ä¸­çš„é…ç½®ï¼‰
        os.environ['OPENAI_API_KEY'] = 'sk-test-key'
        os.environ['OPENAI_BASE_URL'] = 'https://api.openai.com/v1'
        os.environ['ALI_DASHSCOPE_API_KEY'] = 'sk-test-key'
        os.environ['ALI_DASHSCOPE_BASE_URL'] = 'https://dashscope.aliyuncs.com/compatible-mode/v1'

        # åˆ›å»ºVideoRAGå®ä¾‹
        videorag = VideoRAG(
            working_dir="/data/é¡¹ç›®/videoagent/storage/test_caption_fix"
        )

        print("âœ… VideoRAGå®ä¾‹åˆ›å»ºæˆåŠŸ")

        # æ£€æŸ¥caption_model
        if hasattr(videorag, 'caption_model') and videorag.caption_model is not None:
            print("âœ… VideoRAG.caption_modelå·²æ­£ç¡®åˆå§‹åŒ–")
            print(f"   æ¨¡å‹ç±»å‹: {type(videorag.caption_model)}")
            return True
        else:
            print("âŒ VideoRAG.caption_modelæœªæ­£ç¡®åˆå§‹åŒ–")
            return False

    except Exception as e:
        print(f"âŒ VideoRAGæµ‹è¯•å¤±è´¥: {e}")
        # ä¸æ‰“å°å®Œæ•´tracebackä»¥é¿å…å¹²æ‰°
        return False

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹caption_modelä¿®å¤éªŒè¯æµ‹è¯•\n")

    # æµ‹è¯•1ï¼šåŸºç¡€åŠŸèƒ½æµ‹è¯•
    success1 = test_caption_model_only()

    # æµ‹è¯•2ï¼šVideoRAGé›†æˆæµ‹è¯•
    success2 = test_videorag_with_existing_config()

    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"   åŸºç¡€åŠŸèƒ½æµ‹è¯•: {'âœ… é€šè¿‡' if success1 else 'âŒ å¤±è´¥'}")
    print(f"   VideoRAGé›†æˆæµ‹è¯•: {'âœ… é€šè¿‡' if success2 else 'âŒ å¤±è´¥'}")

    if success1 and success2:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼caption_modelä¿®å¤æˆåŠŸã€‚")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥ã€‚")